{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MultiClass_YT_Comment_Sentiment_Classification_BERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1TcVFhxUAK7rT-RRk4LiERSNADibrbLdq",
      "authorship_tag": "ABX9TyM5y3UqjaWbNz57n+Sq3f56",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HereBeCode/StanceDetectionML-Brockport/blob/main/MultiClass_YT_Comment_Sentiment_Classification_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install / Import Modules"
      ],
      "metadata": {
        "id": "8_1xJ-KD-1Vz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQN1MZhlLCDE"
      },
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "QaP9iImxNV5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from datasets import Dataset\n",
        "import pandas as pd\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "dFPcRmPvLIcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Dataset"
      ],
      "metadata": {
        "id": "wRe3OhYC--4n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"./DataAbortionNLPAugBalanced.csv\"\n",
        "df = pd.read_csv(filename, usecols=['commentTextDisplay','label'], encoding='utf-8')\n",
        "print(df)\n",
        "\n",
        "df = df[(df.label == 0) | (df.label == 1) | (df.label == 2)]\n",
        "df = df.astype({'label': int})\n",
        "print(df)"
      ],
      "metadata": {
        "id": "YNkwleN9LMUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_html_and_other(text):\n",
        "    new_text = re.sub(r'<a href.*\\/a>', ' ', text)\n",
        "    new_text = (new_text.replace('<br /', ' ').\n",
        "                replace('<b>', ' ').\n",
        "                replace('</b>', ' ').\n",
        "                replace('&#39;', \"\\u0027\").\n",
        "                replace('<br >', ' ').\n",
        "                replace('&amp;', '&').\n",
        "                replace('<br>', ' ').\n",
        "                replace('\\u2026', ' ').\n",
        "                replace('&quot;', '\\u0022').\n",
        "                replace('1st', 'first ').\n",
        "                replace('2nd', 'second ').\n",
        "                replace('3rd', 'third ').\n",
        "                replace('100%', 'one hundred percent ')\n",
        "    )\n",
        "    return new_text\n",
        "\n",
        "def cleanTxt(text):\n",
        "    TEXT = text.lower()\n",
        "    TEXT = remove_html_and_other(TEXT)\n",
        "    return TEXT"
      ],
      "metadata": {
        "id": "Mwm4aQNMne-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['commentTextDisplay'] = df['commentTextDisplay'].apply(cleanTxt)\n",
        "print(df)"
      ],
      "metadata": {
        "id": "PVIp-FJ8no4X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_df, remaining_df = train_test_split(df, test_size = 0.2, random_state = 1000)\n",
        "validation_df, test_df = train_test_split(remaining_df, test_size = 0.5, random_state = 1000)\n",
        "print(train_df)\n",
        "print(validation_df)\n",
        "print(test_df)"
      ],
      "metadata": {
        "id": "_Eiiag2vLR-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['label'].value_counts())\n",
        "print(train_df['label'].value_counts())\n",
        "print(validation_df['label'].value_counts())\n",
        "print(test_df['label'].value_counts())"
      ],
      "metadata": {
        "id": "fyiazk3cPdvV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "validation_dataset = Dataset.from_pandas(validation_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "print(train_dataset)\n",
        "print(validation_dataset)\n",
        "print(test_dataset)\n",
        "\n",
        "print(train_dataset.features)"
      ],
      "metadata": {
        "id": "SpEJsoT5Ot5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-Processing Dataset\n",
        "The following steps utilize the tokenizer associated with your pre-trained model to tokenize and prepare the dataset to fit the requirements for tranformer models. That is, the tokenized datasets will contain tensors with the following information: attention mask, input_ids, and label. "
      ],
      "metadata": {
        "id": "z8Kb_5Hf_IqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained('microsoft/deberta-base')"
      ],
      "metadata": {
        "id": "A0z5F9PPNIj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"commentTextDisplay\"], truncation=True)"
      ],
      "metadata": {
        "id": "h2-UpBlgNckI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
        "tokenized_validation_dataset = validation_dataset.map(preprocess_function, batched=True)\n",
        "tokenized_test_dataset = test_dataset.map(preprocess_function, batched=True)"
      ],
      "metadata": {
        "id": "DR-Ya1uTXrWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_train_dataset[0]"
      ],
      "metadata": {
        "id": "GRtI9ES8Xqwl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorWithPadding\n",
        "\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"tf\")"
      ],
      "metadata": {
        "id": "Ip4U8pSpN3Ob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf_train_set = tokenized_train_dataset.to_tf_dataset(\n",
        "    columns=[\"attention_mask\", \"input_ids\", \"label\"],\n",
        "    shuffle=True,\n",
        "    batch_size=4,\n",
        "    collate_fn=data_collator,\n",
        ")\n",
        "\n",
        "tf_validation_set = tokenized_validation_dataset.to_tf_dataset(\n",
        "    columns=[\"attention_mask\", \"input_ids\", \"label\"],\n",
        "    shuffle=False,\n",
        "    batch_size=4,\n",
        "    collate_fn=data_collator\n",
        ")\n",
        "tf_test_set = tokenized_test_dataset.to_tf_dataset(\n",
        "    columns=[\"attention_mask\", \"input_ids\", \"label\"],\n",
        "    shuffle=False,\n",
        "    batch_size=4,\n",
        "    collate_fn=data_collator\n",
        ")"
      ],
      "metadata": {
        "id": "Pspr_qHxYS_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for element in tf_train_set:\n",
        "  print(element)"
      ],
      "metadata": {
        "id": "AxEL7J8_Ug2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Model"
      ],
      "metadata": {
        "id": "7jK1bURI_arq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import create_optimizer\n",
        "import tensorflow as tf\n",
        "\n",
        "batch_size = 4\n",
        "num_epochs = 3\n",
        "batches_per_epoch = len(tokenized_train_dataset) // batch_size\n",
        "total_train_steps = int(batches_per_epoch * num_epochs)\n",
        "optimizer, schedule = create_optimizer(init_lr=2e-5, num_warmup_steps=0, num_train_steps=total_train_steps)"
      ],
      "metadata": {
        "id": "6NxBlCjfOTfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFAutoModelForSequenceClassification\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(\"drive/MyDrive/Models/TF_Abortion_Stance_Detect_DeBERTa\", num_labels=3)\n",
        "#model = TFAutoModelForSequenceClassification.from_pretrained(\"microsoft/deberta-base\", num_labels=3)"
      ],
      "metadata": {
        "id": "LDM6P3LDOc7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import sklearn\n",
        "\n",
        "model.compile(optimizer=optimizer,\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "XcS2JhmcOiYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "vMJ6g91ZQcKR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fit/Fine-Tune Pre-Trained Model with Dataset"
      ],
      "metadata": {
        "id": "-YopgC0__gL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x=tf_train_set, \n",
        "          validation_data=tf_validation_set, \n",
        "          epochs=3)"
      ],
      "metadata": {
        "id": "mNnd8u_pOjru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Predict Sentiment with Single User Input"
      ],
      "metadata": {
        "id": "U8hoOeRh_nSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input = [\"abortion should never be allowed except in the case of rape.\"]"
      ],
      "metadata": {
        "id": "ukNMTIMbcBV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_df = pd.DataFrame(input, columns=['commentTextDisplay'])\n",
        "input_dataset = Dataset.from_pandas(input_df)\n",
        "tokenized_input = input_dataset.map(preprocess_function, batched=True)\n",
        "input_ds = tokenized_input.to_tf_dataset(\n",
        "    columns=[\"attention_mask\", \"input_ids\"],\n",
        "    batch_size = 1\n",
        ")"
      ],
      "metadata": {
        "id": "TF3tJxdi-Sh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy\n",
        "from scipy.special import softmax\n",
        "\n",
        "prediction = model.predict(input_ds)\n",
        "probabilities = softmax(prediction.logits)\n",
        "prediction_label = np.argmax(prediction.logits, axis=1)\n",
        "print(probabilities)\n",
        "print(prediction.logits)"
      ],
      "metadata": {
        "id": "98y_EGSK5klo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_label_to_string(label):\n",
        "  if (label == 0):\n",
        "    return \"Neutral\"\n",
        "  elif (label == 1):\n",
        "    return \"Positive\"\n",
        "  else:\n",
        "    return \"Negative\"\n",
        "\n",
        "print(\"Your input: \" + input[0] + \"\\tPrediction: \" + convert_label_to_string(prediction_label))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWJf3boW-Xic",
        "outputId": "2032e3c4-52d7-4529-b195-5d2ea5b3a86e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your input: abortion should never be allowed except in the case of rape.\tPrediction: Neutral\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Testing And Analysis"
      ],
      "metadata": {
        "id": "cUJdH4T7mk4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(tf_test_set)"
      ],
      "metadata": {
        "id": "7Wo57t1XOHXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(tf_test_set)\n",
        "print(softmax(predictions.logits[0]))\n",
        "probabilities = softmax(predictions.logits)"
      ],
      "metadata": {
        "id": "OKZcNfi3RJoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probabilities = []\n",
        "predictions_labels = []\n",
        "actual_labels = []\n",
        "\n",
        "for x in range(len(predictions['logits'])):\n",
        "  probabilities.append(softmax(predictions.logits[x]))\n",
        "for x in range(len(probabilities)):\n",
        "  predictions_labels.append(np.argmax(probabilities[x]))\n",
        "for x in range(len(test_df)):\n",
        "  actual_labels.append(test_df['label'].iloc[x])"
      ],
      "metadata": {
        "id": "SblMqSZxPR-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create and gather confusion matrix data."
      ],
      "metadata": {
        "id": "6hgwyDZZLzam"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "confusion_matrix = confusion_matrix(actual_labels, predictions_labels)\n",
        "confusion_matrix_display = ConfusionMatrixDisplay.from_predictions(actual_labels, predictions_labels, display_labels = ['Neutral', 'Pro-Choice', 'Pro-Life'], cmap='Greens')"
      ],
      "metadata": {
        "id": "RwfFYCN6jSHz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_positive_indices = []\n",
        "true_negative_indices = []\n",
        "true_neutral_indices = []\n",
        "\n",
        "positive_predicted_as_neutral = []\n",
        "positive_predicted_as_negative = []\n",
        "\n",
        "negative_predicted_as_neutral = []\n",
        "negative_predicted_as_positive =[]\n",
        "\n",
        "neutral_predicted_as_positive = []\n",
        "neutral_predicted_as_negative = []\n",
        "\n",
        "for x in range(len(test_df)):\n",
        "  if (test_df['label'].iloc[x] == predictions_labels[x]):\n",
        "    if (test_df['label'].iloc[x] == 0):\n",
        "      true_neutral_indices.append(x)\n",
        "    elif (test_df['label'].iloc[x] == 1):\n",
        "      true_positive_indices.append(x)\n",
        "    else:\n",
        "      true_negative_indices.append(x)\n",
        "  else:\n",
        "    if (test_df['label'].iloc[x] == 0 and prediction_labels[x] == 1):\n",
        "      neutral_predicted_as_positive.append(x)\n",
        "    elif (test_df['label'].iloc[x] == 0 and prediction_labels[x] == 2):\n",
        "      neutral_predicted_as_negative.append(x)\n",
        "    elif (test_df['label'].iloc[x] == 1 and prediction_labels[x] == 0):\n",
        "      positive_predicted_as_neutral.append(x)\n",
        "    elif (test_df['label'].iloc[x] == 1 and prediction_labels[x] == 2):\n",
        "      positive_predicted_as_negative.append(x)\n",
        "    elif (test_df['label'].iloc[x] == 2 and prediction_labels[x] == 0):\n",
        "      negative_predicted_as_neutral.append(x)\n",
        "    elif (test_df['label'].iloc[x] == 2 and prediction_labels[x] == 1):\n",
        "      negative_predicted_as_positive.append(x)\n",
        "    else:\n",
        "      None\n",
        "\n",
        "print(\"True positive indices:\")\n",
        "print(true_positive_indices)\n",
        "print(\"True negative indices:\")\n",
        "print(true_negative_indices)\n",
        "print(\"True neutral indices:\")\n",
        "print(true_neutral_indices)\n",
        "print(\"Positive comments predicted as neutral indices: \")\n",
        "print(positive_predicted_as_neutral)\n",
        "print(\"Positive comments predicted as negative indices: \")\n",
        "print(positive_predicted_as_negative)\n",
        "print(\"Negative comments predicted as neutral indices: \")\n",
        "print(negative_predicted_as_neutral)\n",
        "print(\"Negative comments predicted as positive indices: \")\n",
        "print(negative_predicted_as_positive)\n",
        "print(\"Neutral comments predicted as positive indices: \")\n",
        "print(neutral_predicted_as_positive)\n",
        "print(\"Neutral comments predicted as negative indices: \")\n",
        "print(neutral_predicted_as_negative)\n"
      ],
      "metadata": {
        "id": "ufGWTGLUbOtC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for x in range(len(true_neutral_indices)):\n",
        "  print(\"Index \" + str(true_neutral_indices[x]) + \": \" + test_df['commentTextDisplay'].iloc[true_neutral_indices[x]])"
      ],
      "metadata": {
        "id": "cU31Lvyed1aS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute accuracy, precision, recall, and F1 score."
      ],
      "metadata": {
        "id": "EfHcmUIvMsO4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "accuracy = accuracy_score(actual_labels, predictions_labels)\n",
        "precision = precision_score(actual_labels, predictions_labels, average = \"macro\")\n",
        "recall = recall_score(actual_labels, predictions_labels, average = \"macro\")\n",
        "f1_score = f1_score(actual_labels, predictions_labels, average = \"macro\")"
      ],
      "metadata": {
        "id": "uBUrVt1XMq5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print dataset and model statistics including breakdown of comments, and model accuracy, precision, recall, and F1 score."
      ],
      "metadata": {
        "id": "xZF7ziG_MLjH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accurary: \" + str(accuracy))\n",
        "print(\"Precision: \" + str(precision))\n",
        "print(\"Recall: \" + str(recall))\n",
        "print(\"F1 Score: \" + str(f1_score))"
      ],
      "metadata": {
        "id": "ELjvXw50JeLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save Model"
      ],
      "metadata": {
        "id": "h2e_Z8kD_0Dq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained('drive/MyDrive/Models/TF_Abortion_Stance_Detect_DeBERTa', save_format='tf')"
      ],
      "metadata": {
        "id": "GskZ60TLghT6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}